# üåê Documentaci√≥n de API

## üìã Resumen

La API de TitanicChat proporciona endpoints para interactuar con el sistema de chat conversacional. Actualmente incluye un endpoint principal para el procesamiento de mensajes a trav√©s de OpenAI.

## üîó Base URL

```
Desarrollo: http://localhost:3000
Producci√≥n: https://tu-dominio.com
```

## üîê Autenticaci√≥n

La API utiliza autenticaci√≥n basada en API keys de OpenAI configuradas en el servidor. No se requiere autenticaci√≥n del cliente.

## üì° Endpoints

### POST /api/chat

Procesa un mensaje de chat y retorna la respuesta del asistente de IA.

#### Request

**URL**: `/api/chat`
**M√©todo**: `POST`
**Content-Type**: `application/json`

#### Headers
```http
Content-Type: application/json
```

#### Body Parameters

| Par√°metro | Tipo | Requerido | Descripci√≥n |
|-----------|------|-----------|-------------|
| `message` | string | ‚úÖ | El mensaje del usuario |
| `history` | OpenAIMessage[] | ‚úÖ | Historial de la conversaci√≥n |

#### OpenAIMessage Structure
```typescript
interface OpenAIMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}
```

#### Ejemplo de Request
```json
{
  "message": "¬øC√≥mo est√° el clima hoy?",
  "history": [
    {
      "role": "user",
      "content": "Hola"
    },
    {
      "role": "assistant", 
      "content": "¬°Hola! ¬øEn qu√© puedo ayudarte hoy?"
    }
  ]
}
```

#### Response

**Status Code**: `200 OK`
**Content-Type**: `application/json`

#### Response Structure
```typescript
interface OpenAIResponse {
  choices: Array<{
    message: {
      content: string;
      role: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}
```

#### Ejemplo de Response
```json
{
  "choices": [
    {
      "message": {
        "content": "Lo siento, no tengo acceso a informaci√≥n meteorol√≥gica en tiempo real. Te recomiendo consultar un servicio meteorol√≥gico local o una aplicaci√≥n del clima para obtener informaci√≥n actualizada sobre el clima en tu √°rea.",
        "role": "assistant"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 45,
    "completion_tokens": 38,
    "total_tokens": 83
  }
}
```

## üö® C√≥digos de Error

### 400 Bad Request
**Descripci√≥n**: Solicitud malformada o par√°metros faltantes

#### Causas Comunes:
- Mensaje vac√≠o o faltante
- Formato JSON inv√°lido
- Par√°metros requeridos faltantes

#### Ejemplo de Response:
```json
{
  "error": "El mensaje es requerido"
}
```

### 401 Unauthorized
**Descripci√≥n**: API key inv√°lida o faltante

#### Causas Comunes:
- API key de OpenAI no configurada
- API key inv√°lida o expirada
- Problemas de configuraci√≥n del servidor

#### Ejemplo de Response:
```json
{
  "error": "API key de OpenAI no configurada"
}
```

### 429 Too Many Requests
**Descripci√≥n**: L√≠mite de rate limiting excedido

#### Causas Comunes:
- Demasiadas solicitudes por minuto
- L√≠mites de OpenAI excedidos
- Rate limiting del servidor

#### Ejemplo de Response:
```json
{
  "error": "Demasiadas solicitudes. Intenta m√°s tarde."
}
```

### 500 Internal Server Error
**Descripci√≥n**: Error interno del servidor

#### Causas Comunes:
- Error en la comunicaci√≥n con OpenAI
- Problemas de configuraci√≥n del servidor
- Errores no manejados

#### Ejemplo de Response:
```json
{
  "error": "Error interno del servidor"
}
```

### 503 Service Unavailable
**Descripci√≥n**: Servicio temporalmente no disponible

#### Causas Comunes:
- OpenAI API no disponible
- Mantenimiento del servidor
- Sobrecarga del sistema

#### Ejemplo de Response:
```json
{
  "error": "Servicio temporalmente no disponible"
}
```

## üìä L√≠mites y Cuotas

### Rate Limiting
- **L√≠mite actual**: Sin l√≠mite implementado
- **Recomendaci√≥n**: Implementar l√≠mites por IP/sesi√≥n
- **Futuro**: 100 requests/minuto por IP

### L√≠mites de OpenAI
- **Modelo**: GPT-3.5-turbo
- **Max tokens**: 1000 por respuesta
- **L√≠mites de cuenta**: Seg√∫n plan de OpenAI

### L√≠mites de Contenido
- **Longitud m√°xima del mensaje**: 4000 caracteres
- **Historial m√°ximo**: 50 mensajes
- **Timeout**: 30 segundos

## üîß Configuraci√≥n

### Variables de Entorno Requeridas
```env
OPENAI_API_KEY=sk-proj-...
```

### Variables de Entorno Opcionales
```env
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7
OPENAI_TIMEOUT=30000
```

## üìù Ejemplos de Uso

### JavaScript/TypeScript
```typescript
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'Hola, ¬øc√≥mo est√°s?',
    history: []
  })
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

### cURL
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Expl√≠came qu√© es React",
    "history": []
  }'
```

### Python
```python
import requests

response = requests.post('http://localhost:3000/api/chat', 
  json={
    'message': '¬øQu√© es la inteligencia artificial?',
    'history': []
  }
)

data = response.json()
print(data['choices'][0]['message']['content'])
```

## üß™ Testing

### Test de Conectividad
```bash
# Verificar que el endpoint responde
curl -I http://localhost:3000/api/chat
```

### Test B√°sico
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"test","history":[]}'
```

### Test de Error
```bash
# Test con mensaje vac√≠o (debe retornar 400)
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"","history":[]}'
```

## üìà Monitoreo

### M√©tricas Recomendadas
- **Response time**: Tiempo de respuesta promedio
- **Error rate**: Porcentaje de errores
- **Request volume**: N√∫mero de requests por minuto
- **Token usage**: Consumo de tokens de OpenAI

### Logs de Ejemplo
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "method": "POST",
  "url": "/api/chat",
  "status": 200,
  "response_time": 1500,
  "tokens_used": 85,
  "user_ip": "192.168.1.1"
}
```

## üîÆ Roadmap de la API

### Versi√≥n 1.1 (Pr√≥ximamente)
- [ ] Rate limiting implementado
- [ ] Autenticaci√≥n de usuarios
- [ ] M√©tricas de uso
- [ ] Caching de respuestas

### Versi√≥n 1.2 (Futuro)
- [ ] Streaming de respuestas
- [ ] M√∫ltiples modelos de IA
- [ ] Webhooks
- [ ] API versioning

### Versi√≥n 2.0 (Futuro)
- [ ] GraphQL endpoint
- [ ] Persistencia de conversaciones
- [ ] An√°lisis de sentimientos
- [ ] Integraci√≥n con bases de datos

## üîí Seguridad

### Mejores Pr√°cticas
- ‚úÖ API keys almacenadas en servidor
- ‚úÖ Validaci√≥n de entrada
- ‚úÖ Manejo de errores seguro
- ‚ö†Ô∏è Rate limiting (pendiente)
- ‚ö†Ô∏è Sanitizaci√≥n de entrada (pendiente)

### Recomendaciones
1. **Implementar HTTPS** en producci√≥n
2. **Configurar CORS** apropiadamente
3. **Implementar rate limiting**
4. **Logs de seguridad**
5. **Monitoreo de anomal√≠as**

## üìû Soporte

### Reportar Problemas
- Incluir request/response completos
- C√≥digo de error espec√≠fico
- Timestamp del error
- Informaci√≥n del entorno

### Contacto
- **Documentaci√≥n**: [Ver documentaci√≥n t√©cnica](../technical/)
- **Issues**: Reportar en el repositorio
- **Soporte**: Contactar al equipo de desarrollo

---

**Versi√≥n de la API**: 1.0.0
**√öltima actualizaci√≥n**: Enero 2024 